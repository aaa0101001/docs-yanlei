问题一：RabbitMQ 怎么样保证消息不丢失
	1、事务机制
		RabbitMQ 提供了事务功能，生产者发送数据之前开启 RabbitMQ 事务channel.txSelect，然后发送消息，如果消息没有成功被RabbitMQ接收到，那么生产者会收到异常报错，此时就可以回滚事务channel.txRollback，然后重试发送消息；如果收到了消息，那么可以提交事务channel.txCommit。
	2、确认机制 、 mq接收到生产者发送的消息 ，会返回ack告知生产者是否是否收到这个消息，如果没收到会重试
		RabbitMQ可以开启confirm模式，在生产者那里设置开启confirm模式之后，生产者每次写的消息都会分配一个唯一的 id，如果消息成功写入RabbitMQ 中，RabbitMQ 会给生产者回传一个ack消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你的一个nack接口，告诉你这个消息接收失败，生产者可以发送。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么可以重发。
	总结：RabbitMQ的事务机制是同步的，很耗型能，会降低RabbitMQ的吞吐量。confirm机制是异步的，生成者发送完一个消息之后，不需要等待RabbitMQ的回调，就可以发送下一个消息，当RabbitMQ成功接收到消息之后会自动异步的回调生产者的一个接口返回成功与否的消息。

问题二：RabbitMQ接收到消息之后丢失了消息
a、丢失的原因：RabbitMQ接收到生产者发送过来的消息，是存在内存中的，如果没有被消费完，此时RabbitMQ宕机了，那么再次启动的时候，原来内存中的那些消息都丢失了。
b、解决办法：开启RabbitMQ的持久化。当生产者把消息成功写入RabbitMQ之后，RabbitMQ就把消息持久化到磁盘。结合上面的说到的confirm机制，只有当消息成功持久化磁盘之后，才会回调生产者的接口返回ack消息，否则都算失败，生产者会重新发送。存入磁盘的消息不会丢失，就算RabbitMQ挂掉了，重启之后，他会读取磁盘中的消息，不会导致消息的丢失。
c、持久化的配置：
第一点是创建 queue 的时候将其设置为持久化，这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的。
第二个是发送消息的时候将消息的deliveryMode设置为 2，就是将消息设置为持久化的，此时 RabbitMQ 就会将消息持久化到磁盘上去。
注意：持久化要起作用必须同时设置这两个持久化才行，RabbitMQ 哪怕是挂了，再次重启，也会从磁盘上重启恢复 queue，恢复这个 queue 里的数据。

3 消费者弄丢了消息
a、丢失的原因：如果RabbitMQ成功的把消息发送给了消费者，那么RabbitMQ的ack机制会自动的返回成功，表明发送消息成功，下次就不会发送这个消息。但如果就在此时，消费者还没处理完该消息，然后宕机了，那么这个消息就丢失了。
b、解决的办法：简单来说，就是必须关闭 RabbitMQ 的自动ack，可以通过一个 api 来调用就行，然后每次在自己代码里确保处理完的时候，再在程序里ack一把。这样的话，如果你还没处理完，不就没有ack了？那 RabbitMQ 就认为你还没处理完，这个时候 RabbitMQ 会把这个消费分配给别的 consumer 去处理，消息是不会丢的。

二、如何防止重复消费
先说为什么会重复消费：正常情况下，消费者在消费消息的时候，消费完毕后，会发送一个确认消息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除；但是因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将消息分发给其他的消费者。

解决思路是：保证消息的唯一性，就算是多次传输，不要让消息的多次消费带来影响；保证消息等幂性；
       解决方法：发送消息时让每个消息携带一个全局的唯一ID，在消费消息时先判断消息是否已经被消费过，保证消息消费逻辑的幂等性。具体消费过程为：
	1.	消费者获取到消息后先根据id去查询redis/db是否存在该消息
	2.	如果不存在，则正常消费，消费完毕后写入redis/db
	3.	如果存在，则证明消息被消费过，直接丢弃

在消息生产时，MQ内部针对每条生产者发送的消息生成一个inner-msg-id，作为去重和幂等的依据（消息投递失败并重传），避免重复的消息进入队列；
在消息消费时，要求消息体中必须要有一个bizId（对于同一业务全局唯一，如支付ID、订单ID、帖子ID等）作为去重和幂等的依据，避免同一条消息被重复消费。
这个问题针对业务场景来答分以下几点：

如果消息是做数据库的insert操作，给这个消息做一个唯一主键，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。

如果消息是做redis的set的操作，不用解决，因为无论set几次结果都是一样的，set操作本来就算幂等操作。

如果以上两种情况还不行，可以准备一个第三方介质,来做消费记录。以redis为例，给消息分配一个全局id，只要消费过该消息，将<id,message>以K-V形式写入redis。那消费者开始消费前，先去redis中查询有没消费记录即可。

消费端怎么进行限流？
当 RabbitMQ 服务器积压大量消息时，队列里的消息会大量涌入消费端，可能导致消费端服务器奔溃。这种情况下需要对消费端限流。
Spring RabbitMQ 提供参数 prefetch 可以设置单个请求处理的消息个数。如果消费者同时处理的消息到达最大值的时候，则该消费者会阻塞，不会消费新的消息，直到有消息 ack 才会消费新的消息。
开启消费端限流：
	##在单个请求中处理的消息个数，unack的最大数量
	spring.rabbitmq.listener.simple.prefetch=2

原生 RabbitMQ 还提供 prefetchSize 和 global 两个参数。Spring RabbitMQ没有这两个参数。
	//单条消息大小限制，0代表不限制
	//global：限制限流功能是channel级别的还是consumer级别。当设置为false，consumer级别，限流功能生效，设置为true没有了限流功能，因为channel级别尚未实现。
	void basicQos(int prefetchSize, int prefetchCount, boolean global) throws IOException;

什么是死信队列？
消费失败的消息存放的队列。
消息消费失败的原因：
	•	消息被拒绝并且消息没有重新入队（requeue=false）
	•	消息超时未消费
	•	达到最大队列长度
设置死信队列的 exchange 和 queue，然后进行绑定
在普通队列加上两个参数，绑定普通队列到死信队列。当消息消费失败时，消息会被路由到死信队列。

RabbitMQ保证消息顺序性
RabbitMQ：拆分多个queue，每个queue一个consumer，就是多一些queue而已，确实是麻烦，或者就是一个queue，但是对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理。
下图为：一个consumer 对应 一个 queue，这样就保证了消息消费的顺序性。

MQ（Message Queue）消息队列，是基础数据结构中“先进先出”的一种数据结构。
指把要传输的数据（消息）放在队列中，用队列机制来实现消息传递——生产者产生消息并把消息放入队列，然后由消费者去处理。
消费者可以到指定队列拉取消息，或者订阅相应的队列，由MQ服务端给其推送消息。

消息队列中间件是分布式系统中重要的组件，主要解决应用解耦，异步消息，流量削锋等问题，实现高性能，高可用，可伸缩和最终一致性架构。
解耦：一个业务需要多个模块共同实现，或者一条消息有多个系统需要对应处理，只需要主业务完成以后，发送一条MQ，其余模块消费MQ消息，即可实现业务，降低模块之间的耦合。
异步：主业务执行结束后从属业务通过MQ，异步执行，减低业务的响应时间，提高用户体验。
削峰：高并发情况下，业务异步处理，提供高峰期业务处理能力，避免系统瘫痪。

135. rabbitmq 的使用场景有哪些？
①. 跨系统的异步通信，所有需要异步交互的地方都可以使用消息队列。就像我们除了打电话（同步）以外，还需要发短信，发电子邮件（异步）的通讯方式。
②. 多个应用之间的耦合，由于消息是平台无关和语言无关的，而且语义上也不再是函数调用，因此更适合作为多个应用之间的松耦合的接口。基于消息队列的耦合，不需要发送方和接收方同时在线。在企业应用集成（EAI）中，文件传输，共享数据库，消息队列，远程过程调用都可以作为集成的方法。
③. 应用内的同步变异步，比如订单处理，就可以由前端应用将订单信息放到队列，后端应用从队列里依次获得消息处理，高峰时的大量订单可以积压在队列里慢慢处理掉。由于同步通常意味着阻塞，而大量线程的阻塞会降低计算机的性能。
④. 消息驱动的架构（EDA），系统分解为消息队列，和消息制造者和消息消费者，一个处理流程可以根据需要拆成多个阶段（Stage），阶段之间用队列连接起来，前一个阶段处理的结果放入队列，后一个阶段从队列中获取消息继续处理。
⑤. 应用需要更灵活的耦合方式，如发布订阅，比如可以指定路由规则。
⑥. 跨局域网，甚至跨城市的通讯（CDN行业），比如北京机房与广州机房的应用程序的通信。

136. rabbitmq 有哪些重要的角色？
RabbitMQ 中重要的角色有：生产者、消费者和代理：
	•	生产者：消息的创建者，负责创建和推送数据到消息服务器；
	•	消费者：消息的接收方，用于处理数据和确认消息；
	•	代理：就是 RabbitMQ 本身，用于扮演“快递”的角色，本身不生产消息，只是扮演“快递”的角色。

137. rabbitmq 有哪些重要的组件？
	•	ConnectionFactory（连接管理器）：应用程序与Rabbit之间建立连接的管理器，程序代码中使用。
	•	Channel（信道）：消息推送使用的通道。
	•	Exchange（交换器）：用于接受、分配消息。
	•	Queue（队列）：用于存储生产者的消息。
	•	RoutingKey（路由键）：用于把生成者的数据分配到交换器上。
	•	BindingKey（绑定键）：用于把交换器的消息绑定到队列上。

138. rabbitmq 中 vhost 的作用是什么？
vhost 可以理解为虚拟 broker ，即 mini-RabbitMQ server。其内部均含有独立的 queue、exchange 和 binding 等，但最最重要的是，其拥有独立的权限系统，可以做到 vhost 范围的用户控制。当然，从 RabbitMQ 的全局角度，vhost 可以作为不同权限隔离的手段（一个典型的例子就是不同的应用可以跑在不同的 vhost 中）。

139. rabbitmq 的消息是怎么发送的？
首先客户端必须连接到 RabbitMQ 服务器才能发布和消费消息，客户端和 rabbit server 之间会创建一个 tcp 连接，一旦 tcp 打开并通过了认证（认证就是你发送给 rabbit 服务器的用户名和密码），你的客户端和 RabbitMQ 就创建了一条 amqp 信道（channel），信道是创建在“真实” tcp 上的虚拟连接，amqp 命令都是通过信道发送出去的，每个信道都会有一个唯一的 id，不论是发布消息，订阅队列都是通过这个信道完成的。

140. rabbitmq 怎么保证消息的稳定性？
	•	提供了事务的功能。
	•	通过将 channel 设置为 confirm（确认）模式。

141. rabbitmq 怎么避免消息丢失？
	1.	消息持久化
	2.	ACK确认机制
	3.	设置集群镜像模式
	4.	消息补偿机制

142. 要保证消息持久化成功的条件有哪些？
	1.	声明队列必须设置持久化 durable 设置为 true.
	2.	消息推送投递模式必须设置持久化，deliveryMode 设置为 2（持久）。
	3.	消息已经到达持久化交换器。
	4.	消息已经到达持久化队列。
以上四个条件都满足才能保证消息持久化成功。

143. rabbitmq 持久化有什么缺点？
持久化的缺地就是降低了服务器的吞吐量，因为使用的是磁盘而非内存存储，从而降低了吞吐量。可尽量使用 ssd 硬盘来缓解吞吐量的问题。

144. rabbitmq 有几种广播类型？
三种广播模式：
	1.	fanout: 所有bind到此exchange的queue都可以接收消息（纯广播，绑定到RabbitMQ的接受者都能收到消息）； 
	2.	direct: 通过routingKey和exchange决定的那个唯一的queue可以接收消息； 
	3.	topic:所有符合routingKey(此时可以是一个表达式)的routingKey所bind的queue可以接收消息；

145. rabbitmq 怎么实现延迟消息队列？
	1.	通过消息过期后进入死信交换器，再由交换器转发到延迟消费队列，实现延迟功能；
	2.	使用 RabbitMQ-delayed-message-exchange 插件实现延迟功能。

146. rabbitmq 集群有什么用？
集群主要有以下两个用途：
	•	高可用：某个服务器出现问题，整个 RabbitMQ 还可以继续使用；
	•	高容量：集群可以承载更多的消息量。

147. rabbitmq 节点的类型有哪些？
	•	磁盘节点：消息会存储到磁盘。
	•	内存节点：消息都存储在内存中，重启服务器消息丢失，性能高于磁盘类型。

148. rabbitmq 集群搭建需要注意哪些问题？
	•	各节点之间使用“--link”连接，此属性不能忽略。
	•	各节点使用的 erlang cookie 值必须相同，此值相当于“秘钥”的功能，用于各节点的认证。
	•	整个集群中必须包含一个磁盘节点。

149. rabbitmq 每个节点是其他节点的完整拷贝吗？为什么？
不是，原因有以下两个：
	1.	存储空间的考虑：如果每个节点都拥有所有队列的完全拷贝，这样新增节点不但没有新增存储空间，反而增加了更多的冗余数据；
	2.	性能的考虑：如果每条消息都需要完整拷贝到每一个集群节点，那新增节点并没有提升处理消息的能力，最多是保持和单节点相同的性能甚至是更糟。

150. rabbitmq 集群中唯一一个磁盘节点崩溃了会发生什么情况？
如果唯一磁盘的磁盘节点崩溃了，不能进行以下操作：
	•	不能创建队列
	•	不能创建交换器
	•	不能创建绑定
	•	不能添加用户
	•	不能更改权限
	•	不能添加和删除集群节点
唯一磁盘节点崩溃了，集群是可以保持运行的，但你不能更改任何东西。

151. rabbitmq 对集群节点停止顺序有要求吗？
RabbitMQ 对集群的停止的顺序是有要求的，应该先关闭内存节点，最后再关闭磁盘节点。如果顺序恰好相反的话，可能会造成消息的丢失
消息丢失问题
		RabbitMQ
		1、开启事务模式
		2、消息确认模式
			生产者->MQ->消费者
				生产者->RabbitMQ：发送确认
					@Description 消息发送确认
					 ConfirmCallback  只确认消息是否正确到达 Exchange 中
					 ReturnCallback   消息没有正确到达队列时触发回调，如果正确到达队列不执行
					 * 1. 如果消息没有到exchange,则confirm回调,ack=false
					 * 2. 如果消息到达exchange,则confirm回调,ack=true
					 * 3. exchange到queue成功,则不回调return
					 * 4. exchange到queue失败,则回调return
					有时，业务处理成功，消息也发了，但是我们并不知道消息是否成功到达了rabbitmq，如果由于网络等原因导致业务成功而消息发送失败，那么发送方将出现不一致的问题，此时可以使用rabbitmq的发送确认功能，即要求rabbitmq显式告知我们消息是否已成功发送。
				RabbitMQ：消息持久化
					如果希望RabbitMQ重启之后消息不丢失，那么需要对以下3种实体均配置持久化
					Exchange
					声明exchange时设置持久化（durable = true）并且不自动删除(autoDelete = false)
					Queue
					声明queue时设置持久化（durable = true）并且不自动删除(autoDelete = false)
					message
					发送消息时通过设置deliveryMode=2持久化消息
				RabbitMQ->消费者：手动ack机制
					有时，消息被正确投递到消费方，但是消费方处理失败，那么便会出现消费方的不一致问题。比如:订单已创建的消息发送到用户积分子系统中用于增加用户积分，但是积分消费方处理却都失败了，用户就会问：我购买了东西为什么积分并没有增加呢？
					要解决这个问题，需要引入消费方确认，即只有消息被成功处理之后才告知rabbitmq以ack，否则告知rabbitmq以nack
		Kafka
			消费者：关闭自动提交offset
			kafka
				1、给topic设置relication.factor参数：该值必须大于1，要求每个partition必须有至少两个副本
				2、在kafka服务端时设置min.insync.replicas参数：该值必须大于1，这个是要求一个leader至少感知到有一个follower还跟自己保持联系，没掉队，这样才能确保leader挂了还有一个follower
				3、在producer端设置 acks=all ：这个是要求每条数据，必须是写入所有replica之后，才能认为是写成功了
				4、在producer端设置retries=MAX（很大一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限次重试，卡在这里了
			生产者：若设置 acks=all ，一定不会丢

	消息顺序问题
		RabbitMQ
			拆分多个 queue，每个 queue 一个 consumer，就是多一些 queue 而已，确实是麻烦点；或者就一个 queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的 worker 来处理。
		Kafka
			1、一个 topic，一个 partition，一个 consumer，内部单线程消费，单线程吞吐量太低，一般不	会用这个。
			2、写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。

	如何解决消息队列的延时以及过期失效问题？
	1、死信队列
	2、延时插件

消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？
		造成原因：消费端出现问题，导致消费速度特别慢
		解决：临时紧急扩容，
		1、先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉
		新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。
		然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue。
		接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。
		等快速消费完积压数据之后，得恢复原先部署的架构，重新用原先的 consumer 机器来消费消息

mq 中的消息过期失效了
		造成原因：高峰期如果消息在 queue 中积压超过一定的时间就会被 RabbitMQ 给清理掉
		解决：过了高峰期之后，比如凌晨，手动找出丢失的数据并重新放入mq中消费

		假设你用的是 RabbitMQ，RabbtiMQ 是可以设置过期时间的，也就是 TTL。如果消息在 queue 中积压超过一定的时间就会被 RabbitMQ 给清理掉，这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在 mq 里，而是大量的数据会直接搞丢。

		这个情况下，就不是说要增加 consumer 消费积压的消息，因为实际上没啥积压，而是丢了大量的消息。我们可以采取一个方案，就是批量重导，这个我们之前线上也有类似
的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上12点以后，用户都睡觉了。这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。也只能是这样了。

		假设 1 万个订单积压在 mq 里面，没有处理，其中 1000 个订单都丢了，你只能手动写程序把那 1000 个订单给查出来，手动发到 mq 里去再补一次。

	mq 都快写满了
如果消息积压在 mq 里，你很长时间都没有处理掉，此时导致mq都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧

	五种消息模型
		基本消息模型：生产者–>队列–>消费者
		work消息模型：生产者–>队列–>多个消费者共同消费
		订阅模型-Fanout：广播模式，将消息交给所有绑定到交换机的队列，每个消费者都会收到同一条消息
		订阅模型-Direct：定向，把消息交给符合指定 rotingKey 的队列
		订阅模型-Topic 主题模式：通配符，把消息交给符合routing pattern（路由模式） 的队列
		第6种其实是RPC，并不是MQ





